{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aryan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence-BERT model loaded.\n",
      "ChromaDB client initialized.\n",
      "BLIP model loaded.\n",
      "‚úÖ Video already exists at c:\\Users\\aryan\\Desktop\\Mindflix_AI_Aryan_Jain_B22092\\backend\\..\\data\\videos\\482c5328669da57f350550cdf4c10c3d.mp4. Skipping download.\n",
      "Downloaded video at: c:\\Users\\aryan\\Desktop\\Mindflix_AI_Aryan_Jain_B22092\\backend\\..\\data\\videos\\482c5328669da57f350550cdf4c10c3d.mp4\n",
      "‚úÖ Audio already exists at c:\\Users\\aryan\\Desktop\\Mindflix_AI_Aryan_Jain_B22092\\backend\\..\\data\\audios\\482c5328669da57f350550cdf4c10c3d.wav. Skipping extraction.\n",
      "Audio extracted and converted to .wav at: c:\\Users\\aryan\\Desktop\\Mindflix_AI_Aryan_Jain_B22092\\backend\\..\\data\\audios\\482c5328669da57f350550cdf4c10c3d.wav\n",
      "Whisper model loaded.\n",
      "Loading existing transcript: c:\\Users\\aryan\\Desktop\\Mindflix_AI_Aryan_Jain_B22092\\backend\\..\\data\\transcripts\\482c5328669da57f350550cdf4c10c3d.json\n",
      "Extracting keyframes from video: c:\\Users\\aryan\\Desktop\\Mindflix_AI_Aryan_Jain_B22092\\backend\\..\\data\\videos\\482c5328669da57f350550cdf4c10c3d.mp4\n",
      "7 keyframes extracted.\n",
      "Generating description for frame: c:\\Users\\aryan\\Desktop\\Mindflix_AI_Aryan_Jain_B22092\\backend\\..\\data\\keyframes\\frame_0.jpg\n",
      "Description generated for frame: c:\\Users\\aryan\\Desktop\\Mindflix_AI_Aryan_Jain_B22092\\backend\\..\\data\\keyframes\\frame_0.jpg\n",
      "Generating description for frame: c:\\Users\\aryan\\Desktop\\Mindflix_AI_Aryan_Jain_B22092\\backend\\..\\data\\keyframes\\frame_750.jpg\n",
      "Description generated for frame: c:\\Users\\aryan\\Desktop\\Mindflix_AI_Aryan_Jain_B22092\\backend\\..\\data\\keyframes\\frame_750.jpg\n",
      "Generating description for frame: c:\\Users\\aryan\\Desktop\\Mindflix_AI_Aryan_Jain_B22092\\backend\\..\\data\\keyframes\\frame_1500.jpg\n",
      "Description generated for frame: c:\\Users\\aryan\\Desktop\\Mindflix_AI_Aryan_Jain_B22092\\backend\\..\\data\\keyframes\\frame_1500.jpg\n",
      "Generating description for frame: c:\\Users\\aryan\\Desktop\\Mindflix_AI_Aryan_Jain_B22092\\backend\\..\\data\\keyframes\\frame_2250.jpg\n",
      "Description generated for frame: c:\\Users\\aryan\\Desktop\\Mindflix_AI_Aryan_Jain_B22092\\backend\\..\\data\\keyframes\\frame_2250.jpg\n",
      "Generating description for frame: c:\\Users\\aryan\\Desktop\\Mindflix_AI_Aryan_Jain_B22092\\backend\\..\\data\\keyframes\\frame_3000.jpg\n",
      "Description generated for frame: c:\\Users\\aryan\\Desktop\\Mindflix_AI_Aryan_Jain_B22092\\backend\\..\\data\\keyframes\\frame_3000.jpg\n",
      "Generating description for frame: c:\\Users\\aryan\\Desktop\\Mindflix_AI_Aryan_Jain_B22092\\backend\\..\\data\\keyframes\\frame_3750.jpg\n",
      "Description generated for frame: c:\\Users\\aryan\\Desktop\\Mindflix_AI_Aryan_Jain_B22092\\backend\\..\\data\\keyframes\\frame_3750.jpg\n",
      "Generating description for frame: c:\\Users\\aryan\\Desktop\\Mindflix_AI_Aryan_Jain_B22092\\backend\\..\\data\\keyframes\\frame_4500.jpg\n",
      "Description generated for frame: c:\\Users\\aryan\\Desktop\\Mindflix_AI_Aryan_Jain_B22092\\backend\\..\\data\\keyframes\\frame_4500.jpg\n",
      "üîç Storing metadata for video: https://www.youtube.com/watch?v=Kf57KGwKa0w\n",
      "‚úÖ Metadata already exists for https://www.youtube.com/watch?v=Kf57KGwKa0w. Checking metadata...\n",
      "‚úÖ Metadata exists! Skipping processing.\n",
      "Processed and stored metadata for: https://www.youtube.com/watch?v=Kf57KGwKa0w\n",
      "‚úÖ Video already exists at c:\\Users\\aryan\\Desktop\\Mindflix_AI_Aryan_Jain_B22092\\backend\\..\\data\\videos\\08fc366b5c556ad918a249f0780f78e7.mp4. Skipping download.\n",
      "Downloaded video at: c:\\Users\\aryan\\Desktop\\Mindflix_AI_Aryan_Jain_B22092\\backend\\..\\data\\videos\\08fc366b5c556ad918a249f0780f78e7.mp4\n",
      "‚úÖ Audio already exists at c:\\Users\\aryan\\Desktop\\Mindflix_AI_Aryan_Jain_B22092\\backend\\..\\data\\audios\\08fc366b5c556ad918a249f0780f78e7.wav. Skipping extraction.\n",
      "Audio extracted and converted to .wav at: c:\\Users\\aryan\\Desktop\\Mindflix_AI_Aryan_Jain_B22092\\backend\\..\\data\\audios\\08fc366b5c556ad918a249f0780f78e7.wav\n",
      "Loading existing transcript: c:\\Users\\aryan\\Desktop\\Mindflix_AI_Aryan_Jain_B22092\\backend\\..\\data\\transcripts\\08fc366b5c556ad918a249f0780f78e7.json\n",
      "Extracting keyframes from video: c:\\Users\\aryan\\Desktop\\Mindflix_AI_Aryan_Jain_B22092\\backend\\..\\data\\videos\\08fc366b5c556ad918a249f0780f78e7.mp4\n",
      "8 keyframes extracted.\n",
      "Generating description for frame: c:\\Users\\aryan\\Desktop\\Mindflix_AI_Aryan_Jain_B22092\\backend\\..\\data\\keyframes\\frame_0.jpg\n",
      "Description generated for frame: c:\\Users\\aryan\\Desktop\\Mindflix_AI_Aryan_Jain_B22092\\backend\\..\\data\\keyframes\\frame_0.jpg\n",
      "Generating description for frame: c:\\Users\\aryan\\Desktop\\Mindflix_AI_Aryan_Jain_B22092\\backend\\..\\data\\keyframes\\frame_900.jpg\n",
      "Description generated for frame: c:\\Users\\aryan\\Desktop\\Mindflix_AI_Aryan_Jain_B22092\\backend\\..\\data\\keyframes\\frame_900.jpg\n",
      "Generating description for frame: c:\\Users\\aryan\\Desktop\\Mindflix_AI_Aryan_Jain_B22092\\backend\\..\\data\\keyframes\\frame_1800.jpg\n",
      "Description generated for frame: c:\\Users\\aryan\\Desktop\\Mindflix_AI_Aryan_Jain_B22092\\backend\\..\\data\\keyframes\\frame_1800.jpg\n",
      "Generating description for frame: c:\\Users\\aryan\\Desktop\\Mindflix_AI_Aryan_Jain_B22092\\backend\\..\\data\\keyframes\\frame_2700.jpg\n",
      "Description generated for frame: c:\\Users\\aryan\\Desktop\\Mindflix_AI_Aryan_Jain_B22092\\backend\\..\\data\\keyframes\\frame_2700.jpg\n",
      "Generating description for frame: c:\\Users\\aryan\\Desktop\\Mindflix_AI_Aryan_Jain_B22092\\backend\\..\\data\\keyframes\\frame_3600.jpg\n",
      "Description generated for frame: c:\\Users\\aryan\\Desktop\\Mindflix_AI_Aryan_Jain_B22092\\backend\\..\\data\\keyframes\\frame_3600.jpg\n",
      "Generating description for frame: c:\\Users\\aryan\\Desktop\\Mindflix_AI_Aryan_Jain_B22092\\backend\\..\\data\\keyframes\\frame_4500.jpg\n",
      "Description generated for frame: c:\\Users\\aryan\\Desktop\\Mindflix_AI_Aryan_Jain_B22092\\backend\\..\\data\\keyframes\\frame_4500.jpg\n",
      "Generating description for frame: c:\\Users\\aryan\\Desktop\\Mindflix_AI_Aryan_Jain_B22092\\backend\\..\\data\\keyframes\\frame_5400.jpg\n",
      "Description generated for frame: c:\\Users\\aryan\\Desktop\\Mindflix_AI_Aryan_Jain_B22092\\backend\\..\\data\\keyframes\\frame_5400.jpg\n",
      "Generating description for frame: c:\\Users\\aryan\\Desktop\\Mindflix_AI_Aryan_Jain_B22092\\backend\\..\\data\\keyframes\\frame_6300.jpg\n",
      "Description generated for frame: c:\\Users\\aryan\\Desktop\\Mindflix_AI_Aryan_Jain_B22092\\backend\\..\\data\\keyframes\\frame_6300.jpg\n",
      "üîç Storing metadata for video: https://www.youtube.com/watch?v=ftDsSB3F5kg\n",
      "‚úÖ Metadata already exists for https://www.youtube.com/watch?v=ftDsSB3F5kg. Checking metadata...\n",
      "‚úÖ Metadata exists! Skipping processing.\n",
      "Processed and stored metadata for: https://www.youtube.com/watch?v=ftDsSB3F5kg\n",
      "‚úÖ Video already exists at c:\\Users\\aryan\\Desktop\\Mindflix_AI_Aryan_Jain_B22092\\backend\\..\\data\\videos\\fad8b0dee86393ad9bd51af7aa047f12.mp4. Skipping download.\n",
      "Downloaded video at: c:\\Users\\aryan\\Desktop\\Mindflix_AI_Aryan_Jain_B22092\\backend\\..\\data\\videos\\fad8b0dee86393ad9bd51af7aa047f12.mp4\n",
      "‚úÖ Audio already exists at c:\\Users\\aryan\\Desktop\\Mindflix_AI_Aryan_Jain_B22092\\backend\\..\\data\\audios\\fad8b0dee86393ad9bd51af7aa047f12.wav. Skipping extraction.\n",
      "Audio extracted and converted to .wav at: c:\\Users\\aryan\\Desktop\\Mindflix_AI_Aryan_Jain_B22092\\backend\\..\\data\\audios\\fad8b0dee86393ad9bd51af7aa047f12.wav\n",
      "Loading existing transcript: c:\\Users\\aryan\\Desktop\\Mindflix_AI_Aryan_Jain_B22092\\backend\\..\\data\\transcripts\\fad8b0dee86393ad9bd51af7aa047f12.json\n",
      "Extracting keyframes from video: c:\\Users\\aryan\\Desktop\\Mindflix_AI_Aryan_Jain_B22092\\backend\\..\\data\\videos\\fad8b0dee86393ad9bd51af7aa047f12.mp4\n",
      "10 keyframes extracted.\n",
      "Generating description for frame: c:\\Users\\aryan\\Desktop\\Mindflix_AI_Aryan_Jain_B22092\\backend\\..\\data\\keyframes\\frame_0.jpg\n",
      "Description generated for frame: c:\\Users\\aryan\\Desktop\\Mindflix_AI_Aryan_Jain_B22092\\backend\\..\\data\\keyframes\\frame_0.jpg\n",
      "Generating description for frame: c:\\Users\\aryan\\Desktop\\Mindflix_AI_Aryan_Jain_B22092\\backend\\..\\data\\keyframes\\frame_900.jpg\n",
      "Description generated for frame: c:\\Users\\aryan\\Desktop\\Mindflix_AI_Aryan_Jain_B22092\\backend\\..\\data\\keyframes\\frame_900.jpg\n",
      "Generating description for frame: c:\\Users\\aryan\\Desktop\\Mindflix_AI_Aryan_Jain_B22092\\backend\\..\\data\\keyframes\\frame_1800.jpg\n",
      "Description generated for frame: c:\\Users\\aryan\\Desktop\\Mindflix_AI_Aryan_Jain_B22092\\backend\\..\\data\\keyframes\\frame_1800.jpg\n",
      "Generating description for frame: c:\\Users\\aryan\\Desktop\\Mindflix_AI_Aryan_Jain_B22092\\backend\\..\\data\\keyframes\\frame_2700.jpg\n",
      "Description generated for frame: c:\\Users\\aryan\\Desktop\\Mindflix_AI_Aryan_Jain_B22092\\backend\\..\\data\\keyframes\\frame_2700.jpg\n",
      "Generating description for frame: c:\\Users\\aryan\\Desktop\\Mindflix_AI_Aryan_Jain_B22092\\backend\\..\\data\\keyframes\\frame_3600.jpg\n",
      "Description generated for frame: c:\\Users\\aryan\\Desktop\\Mindflix_AI_Aryan_Jain_B22092\\backend\\..\\data\\keyframes\\frame_3600.jpg\n",
      "Generating description for frame: c:\\Users\\aryan\\Desktop\\Mindflix_AI_Aryan_Jain_B22092\\backend\\..\\data\\keyframes\\frame_4500.jpg\n",
      "Description generated for frame: c:\\Users\\aryan\\Desktop\\Mindflix_AI_Aryan_Jain_B22092\\backend\\..\\data\\keyframes\\frame_4500.jpg\n",
      "Generating description for frame: c:\\Users\\aryan\\Desktop\\Mindflix_AI_Aryan_Jain_B22092\\backend\\..\\data\\keyframes\\frame_5400.jpg\n",
      "Description generated for frame: c:\\Users\\aryan\\Desktop\\Mindflix_AI_Aryan_Jain_B22092\\backend\\..\\data\\keyframes\\frame_5400.jpg\n",
      "Generating description for frame: c:\\Users\\aryan\\Desktop\\Mindflix_AI_Aryan_Jain_B22092\\backend\\..\\data\\keyframes\\frame_6300.jpg\n",
      "Description generated for frame: c:\\Users\\aryan\\Desktop\\Mindflix_AI_Aryan_Jain_B22092\\backend\\..\\data\\keyframes\\frame_6300.jpg\n",
      "Generating description for frame: c:\\Users\\aryan\\Desktop\\Mindflix_AI_Aryan_Jain_B22092\\backend\\..\\data\\keyframes\\frame_7200.jpg\n",
      "Description generated for frame: c:\\Users\\aryan\\Desktop\\Mindflix_AI_Aryan_Jain_B22092\\backend\\..\\data\\keyframes\\frame_7200.jpg\n",
      "Generating description for frame: c:\\Users\\aryan\\Desktop\\Mindflix_AI_Aryan_Jain_B22092\\backend\\..\\data\\keyframes\\frame_8100.jpg\n",
      "Description generated for frame: c:\\Users\\aryan\\Desktop\\Mindflix_AI_Aryan_Jain_B22092\\backend\\..\\data\\keyframes\\frame_8100.jpg\n",
      "üîç Storing metadata for video: https://www.youtube.com/watch?v=kKFrbhZGNNI\n",
      "‚úÖ Metadata already exists for https://www.youtube.com/watch?v=kKFrbhZGNNI. Checking metadata...\n",
      "‚úÖ Metadata exists! Skipping processing.\n",
      "Processed and stored metadata for: https://www.youtube.com/watch?v=kKFrbhZGNNI\n",
      "‚úÖ Video already exists at c:\\Users\\aryan\\Desktop\\Mindflix_AI_Aryan_Jain_B22092\\backend\\..\\data\\videos\\d8ce2817a438e90cc7ae13dd382c4369.mp4. Skipping download.\n",
      "Downloaded video at: c:\\Users\\aryan\\Desktop\\Mindflix_AI_Aryan_Jain_B22092\\backend\\..\\data\\videos\\d8ce2817a438e90cc7ae13dd382c4369.mp4\n",
      "‚úÖ Audio already exists at c:\\Users\\aryan\\Desktop\\Mindflix_AI_Aryan_Jain_B22092\\backend\\..\\data\\audios\\d8ce2817a438e90cc7ae13dd382c4369.wav. Skipping extraction.\n",
      "Audio extracted and converted to .wav at: c:\\Users\\aryan\\Desktop\\Mindflix_AI_Aryan_Jain_B22092\\backend\\..\\data\\audios\\d8ce2817a438e90cc7ae13dd382c4369.wav\n",
      "Loading existing transcript: c:\\Users\\aryan\\Desktop\\Mindflix_AI_Aryan_Jain_B22092\\backend\\..\\data\\transcripts\\d8ce2817a438e90cc7ae13dd382c4369.json\n",
      "Extracting keyframes from video: c:\\Users\\aryan\\Desktop\\Mindflix_AI_Aryan_Jain_B22092\\backend\\..\\data\\videos\\d8ce2817a438e90cc7ae13dd382c4369.mp4\n",
      "9 keyframes extracted.\n",
      "Generating description for frame: c:\\Users\\aryan\\Desktop\\Mindflix_AI_Aryan_Jain_B22092\\backend\\..\\data\\keyframes\\frame_0.jpg\n",
      "Description generated for frame: c:\\Users\\aryan\\Desktop\\Mindflix_AI_Aryan_Jain_B22092\\backend\\..\\data\\keyframes\\frame_0.jpg\n",
      "Generating description for frame: c:\\Users\\aryan\\Desktop\\Mindflix_AI_Aryan_Jain_B22092\\backend\\..\\data\\keyframes\\frame_750.jpg\n",
      "Description generated for frame: c:\\Users\\aryan\\Desktop\\Mindflix_AI_Aryan_Jain_B22092\\backend\\..\\data\\keyframes\\frame_750.jpg\n",
      "Generating description for frame: c:\\Users\\aryan\\Desktop\\Mindflix_AI_Aryan_Jain_B22092\\backend\\..\\data\\keyframes\\frame_1500.jpg\n",
      "Description generated for frame: c:\\Users\\aryan\\Desktop\\Mindflix_AI_Aryan_Jain_B22092\\backend\\..\\data\\keyframes\\frame_1500.jpg\n",
      "Generating description for frame: c:\\Users\\aryan\\Desktop\\Mindflix_AI_Aryan_Jain_B22092\\backend\\..\\data\\keyframes\\frame_2250.jpg\n",
      "Description generated for frame: c:\\Users\\aryan\\Desktop\\Mindflix_AI_Aryan_Jain_B22092\\backend\\..\\data\\keyframes\\frame_2250.jpg\n",
      "Generating description for frame: c:\\Users\\aryan\\Desktop\\Mindflix_AI_Aryan_Jain_B22092\\backend\\..\\data\\keyframes\\frame_3000.jpg\n",
      "Description generated for frame: c:\\Users\\aryan\\Desktop\\Mindflix_AI_Aryan_Jain_B22092\\backend\\..\\data\\keyframes\\frame_3000.jpg\n",
      "Generating description for frame: c:\\Users\\aryan\\Desktop\\Mindflix_AI_Aryan_Jain_B22092\\backend\\..\\data\\keyframes\\frame_3750.jpg\n",
      "Description generated for frame: c:\\Users\\aryan\\Desktop\\Mindflix_AI_Aryan_Jain_B22092\\backend\\..\\data\\keyframes\\frame_3750.jpg\n",
      "Generating description for frame: c:\\Users\\aryan\\Desktop\\Mindflix_AI_Aryan_Jain_B22092\\backend\\..\\data\\keyframes\\frame_4500.jpg\n",
      "Description generated for frame: c:\\Users\\aryan\\Desktop\\Mindflix_AI_Aryan_Jain_B22092\\backend\\..\\data\\keyframes\\frame_4500.jpg\n",
      "Generating description for frame: c:\\Users\\aryan\\Desktop\\Mindflix_AI_Aryan_Jain_B22092\\backend\\..\\data\\keyframes\\frame_5250.jpg\n",
      "Description generated for frame: c:\\Users\\aryan\\Desktop\\Mindflix_AI_Aryan_Jain_B22092\\backend\\..\\data\\keyframes\\frame_5250.jpg\n",
      "Generating description for frame: c:\\Users\\aryan\\Desktop\\Mindflix_AI_Aryan_Jain_B22092\\backend\\..\\data\\keyframes\\frame_6000.jpg\n",
      "Description generated for frame: c:\\Users\\aryan\\Desktop\\Mindflix_AI_Aryan_Jain_B22092\\backend\\..\\data\\keyframes\\frame_6000.jpg\n",
      "üîç Storing metadata for video: https://www.youtube.com/watch?v=6qUxwZcTXHY\n",
      "‚úÖ Metadata already exists for https://www.youtube.com/watch?v=6qUxwZcTXHY. Checking metadata...\n",
      "‚úÖ Metadata exists! Skipping processing.\n",
      "Processed and stored metadata for: https://www.youtube.com/watch?v=6qUxwZcTXHY\n",
      "‚úÖ Video already exists at c:\\Users\\aryan\\Desktop\\Mindflix_AI_Aryan_Jain_B22092\\backend\\..\\data\\videos\\2aab073be753413b4a9c63d8b3b25403.mp4. Skipping download.\n",
      "Downloaded video at: c:\\Users\\aryan\\Desktop\\Mindflix_AI_Aryan_Jain_B22092\\backend\\..\\data\\videos\\2aab073be753413b4a9c63d8b3b25403.mp4\n",
      "‚úÖ Audio already exists at c:\\Users\\aryan\\Desktop\\Mindflix_AI_Aryan_Jain_B22092\\backend\\..\\data\\audios\\2aab073be753413b4a9c63d8b3b25403.wav. Skipping extraction.\n",
      "Audio extracted and converted to .wav at: c:\\Users\\aryan\\Desktop\\Mindflix_AI_Aryan_Jain_B22092\\backend\\..\\data\\audios\\2aab073be753413b4a9c63d8b3b25403.wav\n",
      "Transcribing audio: c:\\Users\\aryan\\Desktop\\Mindflix_AI_Aryan_Jain_B22092\\backend\\..\\data\\audios\\2aab073be753413b4a9c63d8b3b25403.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aryan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\whisper\\transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 413\u001b[0m\n\u001b[0;32m    411\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhisper model loaded.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    412\u001b[0m     firstiter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 413\u001b[0m transcript, transcript_times \u001b[38;5;241m=\u001b[39m \u001b[43mtranscribe_audio\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    415\u001b[0m \u001b[38;5;66;03m# Extract keyframes from the video\u001b[39;00m\n\u001b[0;32m    416\u001b[0m keyframes \u001b[38;5;241m=\u001b[39m extract_keyframes(video_path)\n",
      "Cell \u001b[1;32mIn[1], line 158\u001b[0m, in \u001b[0;36mtranscribe_audio\u001b[1;34m(audio_path)\u001b[0m\n\u001b[0;32m    155\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m transcript, transcript_times  \u001b[38;5;66;03m# Return both text and timestamps\u001b[39;00m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTranscribing audio: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maudio_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 158\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mwhisper_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranscribe\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mword_timestamps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;66;03m# Save the transcript and timestamps as a JSON file\u001b[39;00m\n\u001b[0;32m    161\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(TRANSCRIPTS_DIR, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\whisper\\transcribe.py:146\u001b[0m, in \u001b[0;36mtranscribe\u001b[1;34m(model, audio, verbose, temperature, compression_ratio_threshold, logprob_threshold, no_speech_threshold, condition_on_previous_text, initial_prompt, word_timestamps, prepend_punctuations, append_punctuations, clip_timestamps, hallucination_silence_threshold, **decode_options)\u001b[0m\n\u001b[0;32m    142\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    143\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDetecting language using up to the first 30 seconds. Use `--language` to specify the language\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    144\u001b[0m     )\n\u001b[0;32m    145\u001b[0m mel_segment \u001b[38;5;241m=\u001b[39m pad_or_trim(mel, N_FRAMES)\u001b[38;5;241m.\u001b[39mto(model\u001b[38;5;241m.\u001b[39mdevice)\u001b[38;5;241m.\u001b[39mto(dtype)\n\u001b[1;32m--> 146\u001b[0m _, probs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetect_language\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmel_segment\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m decode_options[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlanguage\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(probs, key\u001b[38;5;241m=\u001b[39mprobs\u001b[38;5;241m.\u001b[39mget)\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\whisper\\decoding.py:52\u001b[0m, in \u001b[0;36mdetect_language\u001b[1;34m(model, mel, tokenizer)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# skip encoder forward pass if already-encoded audio features were given\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mel\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m:] \u001b[38;5;241m!=\u001b[39m (model\u001b[38;5;241m.\u001b[39mdims\u001b[38;5;241m.\u001b[39mn_audio_ctx, model\u001b[38;5;241m.\u001b[39mdims\u001b[38;5;241m.\u001b[39mn_audio_state):\n\u001b[1;32m---> 52\u001b[0m     mel \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# forward pass using a single token, startoftranscript\u001b[39;00m\n\u001b[0;32m     55\u001b[0m n_audio \u001b[38;5;241m=\u001b[39m mel\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\whisper\\model.py:201\u001b[0m, in \u001b[0;36mAudioEncoder.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    198\u001b[0m x \u001b[38;5;241m=\u001b[39m (x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositional_embedding)\u001b[38;5;241m.\u001b[39mto(x\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m    200\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks:\n\u001b[1;32m--> 201\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    203\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln_post(x)\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\whisper\\model.py:170\u001b[0m, in \u001b[0;36mResidualAttentionBlock.forward\u001b[1;34m(self, x, xa, mask, kv_cache)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcross_attn:\n\u001b[0;32m    169\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcross_attn(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcross_attn_ln(x), xa, kv_cache\u001b[38;5;241m=\u001b[39mkv_cache)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m--> 170\u001b[0m x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmlp\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmlp_ln\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\whisper\\model.py:46\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m---> 46\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import yt_dlp\n",
    "import chromadb\n",
    "from flask import Flask, request, jsonify\n",
    "from flask_cors import CORS\n",
    "from pathlib import Path\n",
    "import hashlib\n",
    "from transformers import BlipProcessor, BlipForConditionalGeneration, AutoTokenizer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import subprocess\n",
    "import re\n",
    "import json\n",
    "\n",
    "\n",
    "os.environ[\"TEMP\"] = \"D:/temp\"\n",
    "os.environ[\"TMP\"] = \"D:/temp\"\n",
    "os.environ[\"TRANSFORMERS_CACHE\"] = \"D:/whisper_cache\"\n",
    "os.environ[\"TORCH_HOME\"] = \"D:/whisper_cache\"  # ‚úÖ Forces PyTorch models to D drive\n",
    "os.environ[\"HF_HOME\"] = \"D:/whisper_cache\"  # ‚úÖ Hugging Face cache location\n",
    "\n",
    "import whisper\n",
    "\n",
    "app = Flask(__name__)\n",
    "CORS(app)\n",
    "\n",
    "# # Directory setup (make sure these directories are on your D drive)\n",
    "# VIDEO_DIR = \"D:/rag/videos\"\n",
    "# AUDIO_DIR = \"D:/rag/audios\"\n",
    "# KEYFRAMES_DIR = \"D:/rag/keyframes\"\n",
    "# os.makedirs(VIDEO_DIR, exist_ok=True)\n",
    "# os.makedirs(AUDIO_DIR, exist_ok=True)\n",
    "# os.makedirs(KEYFRAMES_DIR, exist_ok=True)\n",
    "\n",
    "# Get the current working directory (where the notebook is running)\n",
    "CURRENT_DIR = os.getcwd()  # This will return the current directory where the notebook is located\n",
    "\n",
    "# Set the data folder as a sibling to the current working directory\n",
    "DATA_DIR = os.path.join(CURRENT_DIR, '..', 'data')  # \"..\" steps up one directory and looks for the \"data\" folder\n",
    "\n",
    "# Define your directories under the 'data' folder\n",
    "VIDEO_DIR = os.path.join(DATA_DIR, \"videos\")\n",
    "AUDIO_DIR = os.path.join(DATA_DIR, \"audios\")\n",
    "KEYFRAMES_DIR = os.path.join(DATA_DIR, \"keyframes\")\n",
    "TRANSCRIPTS_DIR = os.path.join(DATA_DIR, \"transcripts\")\n",
    "os.makedirs(VIDEO_DIR, exist_ok=True)\n",
    "os.makedirs(AUDIO_DIR, exist_ok=True)\n",
    "os.makedirs(KEYFRAMES_DIR, exist_ok=True)\n",
    "os.makedirs(TRANSCRIPTS_DIR, exist_ok=True)\n",
    "\n",
    "# Initialize Sentence-BERT for vectorization\n",
    "sentence_model = SentenceTransformer('all-mpnet-base-v2')  # ‚úÖ More robust retrieval model\n",
    "print(\"Sentence-BERT model loaded.\")\n",
    "\n",
    "# Initialize ChromaDB\n",
    "client = chromadb.PersistentClient(path=\"chromadb\")\n",
    "collection = client.get_or_create_collection(name=\"video_transcripts\")\n",
    "print(\"ChromaDB client initialized.\")\n",
    "\n",
    "# Initialize BLIP for frame descriptions\n",
    "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "print(\"BLIP model loaded.\")\n",
    "\n",
    "# ‚úÖ Load BERT Tokenizer for Sentence Splitting\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\")\n",
    "\n",
    "def generate_video_id(video_url):\n",
    "    \"\"\"Generate a unique video ID using a hash of the URL.\"\"\"\n",
    "    return hashlib.md5(video_url.encode()).hexdigest()\n",
    "\n",
    "def check_video_exists(video_id):\n",
    "    \"\"\"Check if the video transcript, metadata, and video file already exist in ChromaDB.\"\"\"\n",
    "    transcript_path = os.path.join(TRANSCRIPTS_DIR, f\"{video_id}.txt\")\n",
    "    video_path = os.path.join(VIDEO_DIR, f\"{video_id}.mp4\")\n",
    "\n",
    "    # ‚úÖ Get all stored documents\n",
    "    existing_data = collection.get()\n",
    "    existing_ids = set(existing_data.get(\"ids\", []))\n",
    "\n",
    "    # ‚úÖ Ensure all required components exist\n",
    "    if f\"{video_id}_0\" in existing_ids and os.path.exists(transcript_path) and os.path.exists(video_path):\n",
    "        print(f\"‚úÖ Video {video_id} already processed. Skipping...\")\n",
    "        return True  # ‚úÖ Skip reprocessing\n",
    "\n",
    "    return False  # ‚ùå Reprocess video\n",
    "\n",
    "def download_video(video_url, video_id):\n",
    "    \"\"\"Download the full video only if it does not exist.\"\"\"\n",
    "    video_path = os.path.join(VIDEO_DIR, f\"{video_id}.mp4\")  # Use video_id for filename\n",
    "\n",
    "    if os.path.exists(video_path):\n",
    "        print(f\"‚úÖ Video already exists at {video_path}. Skipping download.\")\n",
    "        return video_path  # ‚úÖ Skip re-downloading\n",
    "\n",
    "    print(f\"‚¨áÔ∏è Downloading video from: {video_url}\")\n",
    "\n",
    "    ydl_opts = {\n",
    "        'outtmpl': video_path,  \n",
    "        'format': 'best',\n",
    "        'noplaylist': True,\n",
    "    }\n",
    "\n",
    "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "        ydl.download([video_url])\n",
    "\n",
    "    print(f\"‚úÖ Video downloaded: {video_path}\")\n",
    "    return video_path\n",
    "\n",
    "def sent_tokenize_regex(text):\n",
    "    return re.split(r\"(?<=[.!?])\\s+\", text)\n",
    "\n",
    "def download_audio_from_video(video_id):\n",
    "    \"\"\"Extracts audio from the existing video file and converts it to .wav.\"\"\"\n",
    "    video_path = os.path.join(VIDEO_DIR, f\"{video_id}.mp4\")\n",
    "    audio_path = os.path.join(AUDIO_DIR, f\"{video_id}.wav\")\n",
    "\n",
    "    if os.path.exists(audio_path):\n",
    "        print(f\"‚úÖ Audio already exists at {audio_path}. Skipping extraction.\")\n",
    "        return audio_path  # ‚úÖ Skip re-extraction\n",
    "\n",
    "    print(f\"üéµ Extracting audio from: {video_path} -> {audio_path}\")\n",
    "\n",
    "    command = [\n",
    "        \"ffmpeg\", \"-i\", video_path,  # ‚úÖ Use corrected video file path\n",
    "        \"-vn\",  # Disable video recording (extract only audio)\n",
    "        \"-acodec\", \"pcm_s16le\",  # PCM audio codec for WAV format\n",
    "        \"-ar\", \"16000\",  # Set audio sample rate to 16kHz\n",
    "        \"-ac\", \"1\",  # Mono channel\n",
    "        audio_path  # ‚úÖ Save output to correct filename\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        subprocess.run(command, check=True)\n",
    "        print(f\"‚úÖ Audio extracted and saved as .wav: {audio_path}\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"‚ùå Error during audio extraction: {e}\")\n",
    "        return None  # ‚úÖ Return None on failure\n",
    "\n",
    "    return audio_path\n",
    "def transcribe_audio(audio_path):\n",
    "    \"\"\"Transcribe audio using Whisper and store/reuse transcription with timestamps.\"\"\"\n",
    "    # Define the path to store the transcript\n",
    "    transcript_path = os.path.join(TRANSCRIPTS_DIR, os.path.basename(audio_path).replace(\".wav\", \".json\"))\n",
    "\n",
    "    # Check if transcript already exists\n",
    "    if os.path.exists(transcript_path):\n",
    "        print(f\"Loading existing transcript: {transcript_path}\")\n",
    "        # Load the existing transcript and transcript_times from the saved JSON file\n",
    "        with open(transcript_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            data = json.load(file)\n",
    "            transcript = data[\"text\"]\n",
    "            transcript_times = data[\"timestamps\"]\n",
    "        return transcript, transcript_times  # Return both text and timestamps\n",
    "\n",
    "    print(f\"Transcribing audio: {audio_path}\")\n",
    "    result = whisper_model.transcribe(audio_path, word_timestamps=True)\n",
    "\n",
    "    # Save the transcript and timestamps as a JSON file\n",
    "    os.makedirs(TRANSCRIPTS_DIR, exist_ok=True)\n",
    "    with open(transcript_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        # Store both text and timestamps in the JSON file\n",
    "        json.dump({\n",
    "            \"text\": result[\"text\"],\n",
    "            \"timestamps\": [\n",
    "                {\"start\": segment[\"start\"], \"end\": segment[\"end\"], \"text\": segment[\"text\"]}\n",
    "                for segment in result[\"segments\"]\n",
    "            ]\n",
    "        }, file, ensure_ascii=False, indent=4)\n",
    "\n",
    "    print(f\"Transcript and timestamps saved to: {transcript_path}\")\n",
    "    return result[\"text\"], [\n",
    "        {\"start\": segment[\"start\"], \"end\": segment[\"end\"], \"text\": segment[\"text\"]}\n",
    "        for segment in result[\"segments\"]\n",
    "    ]\n",
    "\n",
    "def extract_keyframes(video_path, interval=30):\n",
    "    \"\"\"Extract keyframes every `interval` seconds\"\"\"\n",
    "    print(f\"Extracting keyframes from video: {video_path}\")\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "    frame_rate = cap.get(cv2.CAP_PROP_FPS)\n",
    "    \n",
    "    frame_count = 0\n",
    "    success, frame = cap.read()\n",
    "    while success:\n",
    "        if frame_count % int(frame_rate * interval) == 0:\n",
    "            frame_file = os.path.join(KEYFRAMES_DIR, f\"frame_{frame_count}.jpg\")\n",
    "            cv2.imwrite(frame_file, frame)\n",
    "            frames.append(frame_file)\n",
    "        success, frame = cap.read()\n",
    "        frame_count += 1\n",
    "    cap.release()\n",
    "    print(f\"{len(frames)} keyframes extracted.\")\n",
    "    return frames\n",
    "\n",
    "def generate_frame_description(frame_path):\n",
    "    \"\"\"Generate a description of the frame using BLIP\"\"\"\n",
    "    print(f\"Generating description for frame: {frame_path}\")\n",
    "    raw_image = Image.open(frame_path).convert(\"RGB\")\n",
    "    inputs = processor(raw_image, return_tensors=\"pt\")\n",
    "    out = model.generate(**inputs)\n",
    "    description = processor.decode(out[0], skip_special_tokens=True)\n",
    "    print(f\"Description generated for frame: {frame_path}\")\n",
    "    return description\n",
    "\n",
    "def sent_tokenize_regex(text):\n",
    "    return re.split(r\"(?<=[.!?])\\s+\", text)\n",
    "\n",
    "# ‚úÖ Improved Chunking using BERT Tokenization\n",
    "def chunk_transcript(transcript, transcript_times, chunk_size=200, overlap=20):\n",
    "    sentences = sent_tokenize_regex(transcript)  # ‚úÖ Use Transformer-based tokenization\n",
    "    chunks, chunk_timestamps = [], []\n",
    "    \n",
    "    temp_chunk, temp_words = [], 0\n",
    "    start_time, end_time = None, None\n",
    "\n",
    "    for sentence in sentences:\n",
    "        words = sentence.split()\n",
    "        temp_chunk.append(sentence)\n",
    "        temp_words += len(words)\n",
    "\n",
    "        if transcript_times:\n",
    "            for seg in transcript_times:\n",
    "                if seg[\"text\"].strip() in sentence:\n",
    "                    if not start_time:\n",
    "                        start_time = seg[\"start\"]\n",
    "                    end_time = seg[\"end\"]\n",
    "\n",
    "        if temp_words >= chunk_size:\n",
    "            chunks.append(\" \".join(temp_chunk))\n",
    "            chunk_timestamps.append({\"start_time\": start_time, \"end_time\": end_time})\n",
    "            temp_chunk = temp_chunk[-overlap:]\n",
    "            temp_words = sum(len(sent.split()) for sent in temp_chunk)\n",
    "            start_time, end_time = None, None\n",
    "\n",
    "    if temp_chunk:\n",
    "        chunks.append(\" \".join(temp_chunk))\n",
    "        chunk_timestamps.append({\"start_time\": start_time, \"end_time\": end_time})\n",
    "\n",
    "    return chunks, chunk_timestamps\n",
    "\n",
    "\n",
    "\n",
    "def store_metadata(video_id, title, description, video_url, transcript, transcript_times, keyframe_descriptions):\n",
    "    \"\"\"Store video transcript metadata in ChromaDB as vectorized data.\"\"\"\n",
    "    print(f\"üîç Storing metadata for video: {title}\")\n",
    "\n",
    "    # ‚úÖ Get existing metadata safely\n",
    "    existing_metadata = collection.get(ids=[f\"{video_id}_0\"])\n",
    "    \n",
    "    if existing_metadata and \"documents\" in existing_metadata and existing_metadata[\"documents\"]:\n",
    "        print(f\"‚úÖ Metadata already exists for {title}. Checking metadata...\")\n",
    "\n",
    "        # ‚úÖ Fix: Check if metadata exists properly\n",
    "        existing_metadatas = existing_metadata.get(\"metadatas\", None)\n",
    "        if existing_metadatas:\n",
    "            print(\"‚úÖ Metadata exists! Skipping processing.\")\n",
    "            return\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è Warning: Metadata is missing! Re-storing metadata...\")\n",
    "\n",
    "    # ‚úÖ Ensure transcript chunks exist before adding to ChromaDB\n",
    "    chunks, chunk_timestamps = chunk_transcript(transcript, transcript_times)\n",
    "\n",
    "    if not chunks:\n",
    "        print(\"‚ùå Error: No transcript chunks available for storage.\")\n",
    "        return\n",
    "\n",
    "    # ‚úÖ Fix: Replace `None` with empty strings or default values\n",
    "    chunk_metadatas = [\n",
    "        {\n",
    "            \"video_url\": video_url or \"Unknown\",  # ‚úÖ Ensure `video_url` is not None\n",
    "            \"start_time\": chunk_timestamps[i][\"start_time\"] if chunk_timestamps[i][\"start_time\"] is not None else 0,\n",
    "            \"end_time\": chunk_timestamps[i][\"end_time\"] if chunk_timestamps[i][\"end_time\"] is not None else 0\n",
    "        }\n",
    "        for i in range(len(chunks))\n",
    "    ]\n",
    "\n",
    "    # ‚úÖ Check if embeddings already exist before inserting\n",
    "    existing_ids = set(collection.get().get(\"ids\", []))  \n",
    "    new_ids = [f\"{video_id}_{i}\" for i in range(len(chunks))]\n",
    "\n",
    "    # ‚úÖ Filter out IDs that already exist\n",
    "    unique_chunks, unique_metadatas, unique_ids = [], [], []\n",
    "    for i, chunk_id in enumerate(new_ids):\n",
    "        if chunk_id not in existing_ids:\n",
    "            unique_chunks.append(chunks[i])\n",
    "            unique_metadatas.append(chunk_metadatas[i])\n",
    "            unique_ids.append(chunk_id)\n",
    "\n",
    "    if unique_chunks:\n",
    "        print(f\"‚úÖ Adding {len(unique_chunks)} new transcript chunks to ChromaDB.\")\n",
    "        chunk_vectors = sentence_model.encode(unique_chunks)\n",
    "\n",
    "        collection.add(\n",
    "            documents=unique_chunks,\n",
    "            metadatas=unique_metadatas,  # ‚úÖ No `None` values now\n",
    "            embeddings=chunk_vectors,\n",
    "            ids=unique_ids,\n",
    "        )\n",
    "    else:\n",
    "        print(\"‚úÖ No new transcript chunks to add.\")\n",
    "\n",
    "    print(f\"‚úÖ Metadata successfully stored for {title}.\")\n",
    "    print(f\"‚úÖ Storing metadata for {video_id}. Metadata: {chunk_metadatas}\")\n",
    "\n",
    "def retrieve_answer(query, confidence_threshold=0.5):  # üîΩ Lowered threshold\n",
    "    query_vector = sentence_model.encode(query)\n",
    "\n",
    "    results = collection.query(\n",
    "        query_embeddings=[query_vector],\n",
    "        n_results=10  \n",
    "    )\n",
    "\n",
    "    print(\"üîç Retrieved Documents:\", results.get(\"documents\", []))\n",
    "    print(\"üîç Retrieved Metadata:\", results.get(\"metadatas\", []))\n",
    "    print(\"üîç Retrieved Similarity Scores:\", results.get(\"distances\", []))\n",
    "\n",
    "    if not results or not results.get(\"documents\") or not results.get(\"metadatas\"):\n",
    "        return \"‚ùå No relevant results found.\"\n",
    "\n",
    "    response = []\n",
    "    for doc_list, metadata_list, score_list in zip(results[\"documents\"], results[\"metadatas\"], results[\"distances\"]):\n",
    "        for doc, metadata, score in zip(doc_list, metadata_list or [{}], score_list):\n",
    "            similarity = score  # ‚úÖ Directly use ChromaDB similarity\n",
    "\n",
    "            print(f\"üîç Checking Score: {similarity} for Document: {doc[:100]}...\")\n",
    "\n",
    "            if similarity < confidence_threshold:  # ‚úÖ Allow lower threshold\n",
    "                continue  \n",
    "\n",
    "            video_url = metadata.get(\"video_url\", \"Unknown Video\")\n",
    "            start_time = metadata.get(\"start_time\", \"Unknown Time\")\n",
    "            response.append((similarity, f\"üé¨ Video URL: {video_url} ‚è≥ Start Time: {start_time}s\\nüìú Excerpt: {doc}\"))\n",
    "\n",
    "    print(\"üîç Filtered Responses:\", response)\n",
    "\n",
    "    return response[0][1] if response else \"‚ùå No high-confidence results found.\"\n",
    "\n",
    "\n",
    "\n",
    "def clear_chromadb():\n",
    "    \"\"\"Completely reset ChromaDB by deleting and recreating the collection.\"\"\"\n",
    "    global collection  # Ensure we're modifying the global variable\n",
    "\n",
    "    try:\n",
    "        # ‚úÖ Delete the entire collection\n",
    "        client.delete_collection(name=\"video_transcripts\")\n",
    "        print(\"‚úÖ ChromaDB collection deleted.\")\n",
    "\n",
    "        # ‚úÖ Recreate the collection (this resets the embedding dimension)\n",
    "        collection = client.get_or_create_collection(name=\"video_transcripts\")\n",
    "        print(\"‚úÖ New ChromaDB collection created with fresh settings.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error while clearing ChromaDB: {e}\")\n",
    "\n",
    "\n",
    "@app.route(\"/query\", methods=[\"POST\"])\n",
    "def query():\n",
    "    data = request.get_json()\n",
    "    queries = data.get(\"queries\", [])  # Accepting a list of queries\n",
    "    responses = []\n",
    "\n",
    "    # Loop through each query and retrieve the answer\n",
    "    for query in queries:\n",
    "        response = retrieve_answer(query)\n",
    "        responses.append(response)\n",
    "\n",
    "    return jsonify({\"responses\": responses})  # Return list of responses\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    firstiter=0\n",
    "    video_links = [\n",
    "        \"https://www.youtube.com/watch?v=Kf57KGwKa0w\",\n",
    "        \"https://www.youtube.com/watch?v=ftDsSB3F5kg\",\n",
    "        \"https://www.youtube.com/watch?v=kKFrbhZGNNI\",\n",
    "        \"https://www.youtube.com/watch?v=6qUxwZcTXHY\",\n",
    "        \"https://www.youtube.com/watch?v=MspNdsh0QcM\"\n",
    "    ]\n",
    "    # video_links = [\n",
    "    #     \"https://www.youtube.com/watch?v=ftDsSB3F5kg\"\n",
    "    # ]\n",
    "    #clear_chromadb()\n",
    "    for link in video_links:\n",
    "\n",
    "        video_id = generate_video_id(link)  # Generate a unique ID for the video\n",
    "    \n",
    "        if check_video_exists(video_id):\n",
    "            print(f\"Skipping {link} (Already Processed)\")\n",
    "            continue  # Skip processing if transcript exists\n",
    "\n",
    "        # ‚úÖ Pass both `link` (video_url) and `video_id`\n",
    "        video_path = download_video(link, video_id)\n",
    "        print(f\"Downloaded video at: {video_path}\")\n",
    "\n",
    "        # Extract and convert audio from the downloaded video\n",
    "        audio_path = download_audio_from_video(video_id)\n",
    "        if audio_path:\n",
    "            print(f\"Audio extracted and converted to .wav at: {audio_path}\")\n",
    "        else:\n",
    "            print(f\"Failed to extract audio for {link}. Skipping.\")\n",
    "            continue\n",
    "        \n",
    "        # Transcribe audio\n",
    "        if(firstiter==0):\n",
    "            whisper_model = whisper.load_model(\"medium\") #Initialize Whisper model\n",
    "            print(\"Whisper model loaded.\")\n",
    "            firstiter=1\n",
    "        transcript, transcript_times = transcribe_audio(audio_path)\n",
    "        \n",
    "        # Extract keyframes from the video\n",
    "        keyframes = extract_keyframes(video_path)\n",
    "        \n",
    "        # Generate descriptions for keyframes\n",
    "        keyframe_descriptions = [generate_frame_description(frame) for frame in keyframes]\n",
    "        \n",
    "        # Store all metadata in ChromaDB\n",
    "        store_metadata(video_id, link, \"Description placeholder\", link, transcript, transcript_times, keyframe_descriptions)\n",
    "        \n",
    "        print(f\"Processed and stored metadata for: {link}\")\n",
    "\n",
    "    # Example User Queries\n",
    "    # test_queries = [\n",
    "    # \"‡§µ‡•Ä‡§°‡§ø‡§Ø‡•ã ‡§¨‡§®‡§æ‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§è‡§ï ‡§Ö‡§ö‡•ç‡§õ‡•Ä ‡§ü‡•Ä‡§Æ ‡§ï‡•ç‡§Ø‡•ã‡§Ç ‡§ú‡§∞‡•Ç‡§∞‡•Ä ‡§π‡•ã‡§§‡•Ä ‡§π‡•à?\",\n",
    "    # \"‡§Ö‡§ö‡•ç‡§õ‡•á ‡§®‡§ø‡§∞‡•ç‡§¶‡•á‡§∂‡§® ‡§ï‡•á ‡§≤‡§ø‡§è ‡§ï‡•ç‡§Ø‡§æ ‡§ö‡•Ä‡§ú‡•á‡§Ç ‡§ú‡§∞‡•Ç‡§∞‡•Ä ‡§π‡•à‡§Ç?\",\n",
    "    # \"‡§µ‡•Ä‡§°‡§ø‡§Ø‡•ã ‡§è‡§°‡§ø‡§ü‡§ø‡§Ç‡§ó ‡§Æ‡•á‡§Ç ‡§∏‡§¨‡§∏‡•á ‡§Æ‡§π‡§§‡•ç‡§µ‡§™‡•Ç‡§∞‡•ç‡§£ ‡§ï‡•ç‡§Ø‡§æ ‡§π‡•ã‡§§‡§æ ‡§π‡•à?\"\n",
    "    # ]\n",
    "\n",
    "    # # Run the retriever on each query\n",
    "    # for query in test_queries:\n",
    "    #     print(f\"üîç **User Query:** {query}\\n\")\n",
    "    #     print(retrieve_answer(query))\n",
    "    #     print(\"=\" * 80)\n",
    "    app.run(host=\"0.0.0.0\", port=8084, debug=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
